# ì˜¨ë¼ì¸ í•™ìŠµ (Online Learning) ê°€ì´ë“œ

**ë‚ ì§œ**: 2026-02-07
**ë²„ì „**: 1.0

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [ì˜¨ë¼ì¸ í•™ìŠµì´ë€?](#ì˜¨ë¼ì¸-í•™ìŠµì´ë€)
3. [ì•„í‚¤í…ì²˜](#ì•„í‚¤í…ì²˜)
4. [ì‚¬ìš© ë°©ë²•](#ì‚¬ìš©-ë°©ë²•)
5. [Domain Adaptation](#domain-adaptation)
6. [ì„±ëŠ¥ ìµœì í™”](#ì„±ëŠ¥-ìµœì í™”)
7. [ì‹¤ì œ ì‚¬ë¡€](#ì‹¤ì œ-ì‚¬ë¡€)

---

## ê°œìš”

ì˜¨ë¼ì¸ í•™ìŠµì€ ë¡œë´‡ì´ ì‹¤ì‹œê°„ìœ¼ë¡œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ëª¨ë¸ì„ ì—…ë°ì´íŠ¸í•˜ì—¬ **í™˜ê²½ ë³€í™”ì— ì ì‘**í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.

### ì£¼ìš” ê¸°ëŠ¥

- âœ… **ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘**: ìˆœí™˜ ë²„í¼ ê¸°ë°˜ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
- âœ… **Incremental Learning**: ëª¨ë¸ fine-tuning (Neural Network, GP)
- âœ… **Domain Adaptation**: ì‹œë®¬ë ˆì´ì…˜ â†’ ì‹¤ì œ ë¡œë´‡ ì „ì´
- âœ… **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: ì ì‘ ì˜¤ì°¨ ì¶”ì  ë° ì‹œê°í™”
- âœ… **ìë™ ì¬í•™ìŠµ**: íŠ¸ë¦¬ê±° ê¸°ë°˜ ëª¨ë¸ ì—…ë°ì´íŠ¸

---

## ì˜¨ë¼ì¸ í•™ìŠµì´ë€?

### ì˜¤í”„ë¼ì¸ vs ì˜¨ë¼ì¸ í•™ìŠµ

| íŠ¹ì§• | ì˜¤í”„ë¼ì¸ í•™ìŠµ | ì˜¨ë¼ì¸ í•™ìŠµ |
|------|---------------|-------------|
| ë°ì´í„° ìˆ˜ì§‘ | ì‚¬ì „ ìˆ˜ì§‘ (ê³ ì •) | ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼ |
| ëª¨ë¸ ì—…ë°ì´íŠ¸ | í•œ ë²ˆ í•™ìŠµ | ì§€ì†ì  fine-tuning |
| í™˜ê²½ ë³€í™” ëŒ€ì‘ | âŒ ë¶ˆê°€ëŠ¥ | âœ… ê°€ëŠ¥ |
| ë©”ëª¨ë¦¬ ì‚¬ìš© | ì „ì²´ ë°ì´í„°ì…‹ | ìˆœí™˜ ë²„í¼ |
| ì ìš© ì‚¬ë¡€ | ë²¤ì¹˜ë§ˆí¬, ì‹œë®¬ë ˆì´ì…˜ | ì‹¤ì œ ë¡œë´‡, ì¥ê¸° ìš´ì˜ |

### ì˜¨ë¼ì¸ í•™ìŠµì´ í•„ìš”í•œ ê²½ìš°

1. **Sim-to-Real Transfer**
   - ì‹œë®¬ë ˆì´ì…˜ì—ì„œ í•™ìŠµí•œ ëª¨ë¸ì„ ì‹¤ì œ ë¡œë´‡ì— ì ìš©
   - Domain shift (ë§ˆì°°, ì§€ì—°, ë…¸ì´ì¦ˆ) ê·¹ë³µ

2. **í™˜ê²½ ë³€í™” ì ì‘**
   - ë°°í„°ë¦¬ ë°©ì „ìœ¼ë¡œ ì¸í•œ ì„±ëŠ¥ ë³€í™”
   - ë°”ë‹¥ ì¬ì§ˆ ë³€ê²½ (ì¹´í« â†’ íƒ€ì¼)
   - í•˜ì¤‘ ë³€í™” (ë¹ˆ â†’ ì ì¬)

3. **ì¥ê¸° ìš´ì˜**
   - ë¶€í’ˆ ë§ˆëª¨
   - ì„¼ì„œ ë“œë¦¬í”„íŠ¸
   - ê³„ì ˆ ë³€í™” (ì˜¨ë„, ìŠµë„)

---

## ì•„í‚¤í…ì²˜

### ì‹œìŠ¤í…œ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Online Learning System                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚ Environment  â”‚ (state, control) â†’ next_state         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚         â”‚                                               â”‚
â”‚         â†“                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚  â”‚ OnlineDataBuffer â”‚                                   â”‚
â”‚  â”‚  - ìˆœí™˜ ë²„í¼     â”‚                                   â”‚
â”‚  â”‚  - í†µê³„ ì—…ë°ì´íŠ¸ â”‚                                   â”‚
â”‚  â”‚  - ë°°ì¹˜ ìƒ˜í”Œë§   â”‚                                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚         â”‚                                               â”‚
â”‚         â†“ (íŠ¸ë¦¬ê±°: ìƒ˜í”Œ Nê°œë§ˆë‹¤)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚  â”‚  OnlineLearner   â”‚                                   â”‚
â”‚  â”‚  - Fine-tuning   â”‚                                   â”‚
â”‚  â”‚  - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ â”‚                                   â”‚
â”‚  â”‚  - ì¬í•™ìŠµ ìŠ¤ì¼€ì¤„ â”‚                                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚         â”‚                                               â”‚
â”‚         â†“                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚  â”‚  Updated Model   â”‚                                   â”‚
â”‚  â”‚  (Neural or GP)  â”‚                                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚         â”‚                                               â”‚
â”‚         â†“                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚  â”‚ MPPI Controller  â”‚                                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### í•µì‹¬ ì»´í¬ë„ŒíŠ¸

#### 1. OnlineDataBuffer

ìˆœí™˜ ë²„í¼ë¡œ ìµœì‹  ë°ì´í„°ë¥¼ ìœ ì§€:

```python
from mppi_controller.learning.online_learner import OnlineDataBuffer

buffer = OnlineDataBuffer(
    state_dim=3,
    control_dim=2,
    buffer_size=1000,  # ìµœëŒ€ 1000 ìƒ˜í”Œ ìœ ì§€
    batch_size=64,
)

# ë°ì´í„° ì¶”ê°€ (FIFO)
buffer.add(state, control, next_state, dt)

# ëœë¤ ë°°ì¹˜ ìƒ˜í”Œë§
batch = buffer.get_batch(batch_size=64)

# ì¬í•™ìŠµ í•„ìš” ì—¬ë¶€ í™•ì¸
if buffer.should_retrain(min_samples=100, retrain_interval=500):
    # ì¬í•™ìŠµ íŠ¸ë¦¬ê±°
    pass
```

**íŠ¹ì§•**:
- FIFO (First-In-First-Out)
- ìë™ í†µê³„ ì—…ë°ì´íŠ¸ (í‰ê· , í‘œì¤€í¸ì°¨)
- íŠ¸ë¦¬ê±° ê¸°ë°˜ ì¬í•™ìŠµ íŒë‹¨

#### 2. OnlineLearner

ì˜¨ë¼ì¸ í•™ìŠµ ê´€ë¦¬ì:

```python
from mppi_controller.learning.online_learner import OnlineLearner

online_learner = OnlineLearner(
    model=neural_model,
    trainer=neural_trainer,
    buffer_size=1000,
    batch_size=64,
    min_samples_for_update=100,  # ìµœì†Œ 100 ìƒ˜í”Œ í•„ìš”
    update_interval=500,          # 500 ìƒ˜í”Œë§ˆë‹¤ ì¬í•™ìŠµ
    verbose=True,
)

# ì‹¤ì‹œê°„ ì œì–´ ë£¨í”„
for t in range(num_steps):
    control = controller.compute_control(state, ref)
    next_state = env.step(control)

    # ë°ì´í„° ì¶”ê°€ (ìë™ ì¬í•™ìŠµ)
    online_learner.add_sample(state, control, next_state, dt)

    state = next_state
```

**íŠ¹ì§•**:
- ìë™ ì¬í•™ìŠµ íŠ¸ë¦¬ê±°
- Fine-tuning (ì ì€ epochë¡œ ë¹ ë¥¸ ì—…ë°ì´íŠ¸)
- ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- ì ì‘ ì˜¤ì°¨ ì¶”ì 

---

## ì‚¬ìš© ë°©ë²•

### ì „ì²´ íŒŒì´í”„ë¼ì¸

```bash
# ì „ì²´ ì˜¨ë¼ì¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
python examples/learned/online_learning_demo.py --all

# ë‹¨ê³„ë³„ ì‹¤í–‰
python examples/learned/online_learning_demo.py --collect-initial  # ì´ˆê¸° ë°ì´í„°
python examples/learned/online_learning_demo.py --train-initial    # ì´ˆê¸° í•™ìŠµ
python examples/learned/online_learning_demo.py --online-learning  # ì˜¨ë¼ì¸ í•™ìŠµ

# ì»¤ìŠ¤í„°ë§ˆì´ì§•
python examples/learned/online_learning_demo.py --all \
    --initial-duration 10 \      # ì´ˆê¸° ë°ì´í„° 10ì´ˆ
    --online-duration 60 \       # ì˜¨ë¼ì¸ í•™ìŠµ 60ì´ˆ
    --initial-epochs 50          # ì´ˆê¸° í•™ìŠµ 50 epochs
```

### ë‹¨ê³„ë³„ ê°€ì´ë“œ

#### Step 1: ì´ˆê¸° ëª¨ë¸ í•™ìŠµ (ì ì€ ë°ì´í„°)

```python
# 1. ì ì€ ë°ì´í„° ìˆ˜ì§‘ (10-30ì´ˆ)
collector = collect_initial_data(duration=10.0)

# 2. ì´ˆê¸° ëª¨ë¸ í•™ìŠµ
trainer = train_initial_model(collector, epochs=50)
```

**ëª©ì **: ì´ˆê¸° "ëŒ€ëµì ì¸" ëª¨ë¸ í™•ë³´

#### Step 2: ì˜¨ë¼ì¸ í•™ìŠµ ì„¤ì •

```python
# ì˜¨ë¼ì¸ í•™ìŠµ ê´€ë¦¬ì ìƒì„±
online_learner = OnlineLearner(
    model=neural_model,
    trainer=trainer,
    buffer_size=500,
    update_interval=100,  # 100 ìƒ˜í”Œë§ˆë‹¤ ì¬í•™ìŠµ
)
```

#### Step 3: ì‹¤ì‹œê°„ ì œì–´ + í•™ìŠµ

```python
for step in range(num_steps):
    # 1. ì œì–´ ê³„ì‚°
    control, info = controller.compute_control(state, reference)

    # 2. í™˜ê²½ ìŠ¤í… (Domain shift í¬í•¨!)
    next_state = simulate_domain_shift(state, control, base_model, dt)

    # 3. ë°ì´í„° ì¶”ê°€ (ìë™ ì¬í•™ìŠµ íŠ¸ë¦¬ê±°)
    online_learner.add_sample(state, control, next_state, dt)

    state = next_state
```

#### Step 4: ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```python
# ì ì‘ ì„±ëŠ¥ í™•ì¸
summary = online_learner.get_performance_summary()
print(f"Total updates: {summary['num_updates']}")
print(f"Latest val loss: {summary['latest_val_loss']:.6f}")
print(f"Improvement: {summary['adaptation_improvement']:.2f}%")
```

---

## Domain Adaptation

### Sim-to-Real Transfer

ì‹œë®¬ë ˆì´ì…˜ ëª¨ë¸ì€ ì‹¤ì œ ë¡œë´‡ê³¼ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤:

| ì°¨ì´ì  | ì‹œë®¬ë ˆì´ì…˜ | ì‹¤ì œ ë¡œë´‡ |
|--------|-----------|----------|
| ë§ˆì°° | ì´ìƒì  | ë†’ìŒ |
| ì§€ì—° | ì—†ìŒ | ì•¡ì¶”ì—ì´í„° ì§€ì—° |
| ë…¸ì´ì¦ˆ | ì—†ìŒ/ì‘ìŒ | ì„¼ì„œ ë…¸ì´ì¦ˆ |
| ë¹„ì„ í˜•ì„± | ê°„ë‹¨ | ë³µì¡ |

### Domain Shift ì‹œë®¬ë ˆì´ì…˜

ë°ëª¨ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì´ domain shiftë¥¼ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤:

```python
def simulate_domain_shift(state, control, base_model, dt, noise_std=0.05):
    # ê¸°ë³¸ ë™ì—­í•™
    next_state = base_model.step(state, control, dt)

    # 1. ë§ˆì°° ì¦ê°€ (95% ì†ë„)
    friction_factor = 0.95
    next_state[:2] = state[:2] + (next_state[:2] - state[:2]) * friction_factor

    # 2. ì•¡ì¶”ì—ì´í„° bias
    actuator_bias = np.array([0.05, 0.02])
    biased_control = control + actuator_bias
    biased_next_state = base_model.step(state, biased_control, dt)
    next_state = (next_state + biased_next_state) / 2

    # 3. ì¸¡ì • ë…¸ì´ì¦ˆ
    measurement_noise = np.random.normal(0, noise_std, next_state.shape)
    next_state += measurement_noise

    return next_state
```

### Residual Learningìœ¼ë¡œ ì ì‘

```python
# ë¬¼ë¦¬ ëª¨ë¸ + í•™ìŠµ ë³´ì •
residual_model = ResidualDynamics(
    base_model=kinematic_model,  # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë¸
    residual_fn=neural_residual,  # ì˜¨ë¼ì¸ í•™ìŠµëœ ë³´ì •
)

# ì‹¤ì œ ë¡œë´‡ì—ì„œ:
# residual_fn = ì‹¤ì œ ë™ì—­í•™ - ì‹œë®¬ë ˆì´ì…˜ ë™ì—­í•™
```

---

## ì„±ëŠ¥ ìµœì í™”

### ì¬í•™ìŠµ ì£¼ê¸° ì¡°ì •

```python
online_learner = OnlineLearner(
    # ...
    min_samples_for_update=100,  # ìµœì†Œ 100 ìƒ˜í”Œ
    update_interval=500,          # 500 ìƒ˜í”Œë§ˆë‹¤
)
```

**Trade-off**:
- **ì§§ì€ ì£¼ê¸°** (100-200 ìƒ˜í”Œ):
  - âœ… ë¹ ë¥¸ ì ì‘
  - âŒ ê³„ì‚° ë¶€ë‹´ ì¦ê°€
  - ì¶”ì²œ: ì´ˆê¸° ì ì‘ ë‹¨ê³„

- **ê¸´ ì£¼ê¸°** (500-1000 ìƒ˜í”Œ):
  - âœ… ê³„ì‚° íš¨ìœ¨ì 
  - âŒ ëŠë¦° ì ì‘
  - ì¶”ì²œ: ì•ˆì •í™” í›„

### ë°°ì¹˜ í¬ê¸° ì¡°ì •

```python
buffer = OnlineDataBuffer(
    # ...
    batch_size=32,  # ì‘ì€ ë°°ì¹˜ = ë¹ ë¥¸ ì—…ë°ì´íŠ¸
)
```

- **ì‘ì€ ë°°ì¹˜** (16-32): ë¹ ë¥¸ ì—…ë°ì´íŠ¸, ë…¸ì´ì¦ˆ ë§ìŒ
- **í° ë°°ì¹˜** (64-128): ì•ˆì •ì , ëŠë¦¼

### Fine-tuning Epochs

```python
online_learner.update_model(num_epochs=5)  # ì§§ì€ fine-tuning
```

- **ì§§ì€ epochs** (5-10): ë¹ ë¦„, ê³¼ì í•© ìœ„í—˜ ë‚®ìŒ
- **ê¸´ epochs** (20-50): ëŠë¦¼, ê³¼ì í•© ìœ„í—˜

---

## ì‹¤ì œ ì‚¬ë¡€

### ì‚¬ë¡€ 1: ì‹¤ë‚´ ë¡œë´‡ ì ì‘

**ì‹œë‚˜ë¦¬ì˜¤**: ì¹´í« â†’ íƒ€ì¼ ë°”ë‹¥ ë³€ê²½

```
ì´ˆê¸° (ì¹´í«):
  - RMSE: 0.15m
  - ë§ˆì°°: ë†’ìŒ

ë°”ë‹¥ ë³€ê²½ (íƒ€ì¼):
  - RMSE: 0.45m âš ï¸ (ê¸‰ê²©í•œ ì„±ëŠ¥ ì €í•˜)

ì˜¨ë¼ì¸ í•™ìŠµ í›„ (100 ìƒ˜í”Œ):
  - RMSE: 0.18m âœ… (60% íšŒë³µ)

ì˜¨ë¼ì¸ í•™ìŠµ í›„ (500 ìƒ˜í”Œ):
  - RMSE: 0.12m âœ… (ì™„ì „ ì ì‘!)
```

### ì‚¬ë¡€ 2: ë°°í„°ë¦¬ ë°©ì „

**ì‹œë‚˜ë¦¬ì˜¤**: 100% â†’ 20% ë°°í„°ë¦¬

```
ì´ˆê¸° (100% ë°°í„°ë¦¬):
  - ìµœëŒ€ ì†ë„: 1.0 m/s
  - ì‘ë‹µ ì‹œê°„: 50ms

ë°°í„°ë¦¬ ë°©ì „ (20%):
  - ìµœëŒ€ ì†ë„: 0.7 m/s
  - ì‘ë‹µ ì‹œê°„: 150ms

ì˜¨ë¼ì¸ í•™ìŠµ:
  - ëª¨ë¸ì´ ê°ì†Œëœ ì„±ëŠ¥ í•™ìŠµ
  - ì œì–´ ì „ëµ ìë™ ì¡°ì •
  - ì—¬ì „íˆ ì•ˆì •ì  ì¶”ì  ìœ ì§€
```

### ì‚¬ë¡€ 3: í•˜ì¤‘ ë³€í™”

**ì‹œë‚˜ë¦¬ì˜¤**: ë¹ˆ ë¡œë´‡ â†’ 10kg ì ì¬

```
ì´ˆê¸° (ë¹ˆ ë¡œë´‡):
  - ê´€ì„±: ë‚®ìŒ
  - ê°€ì†: ë¹ ë¦„

í•˜ì¤‘ ì ì¬ (10kg):
  - ê´€ì„±: 2ë°° ì¦ê°€
  - ê°€ì†: ëŠë¦¼

ì˜¨ë¼ì¸ í•™ìŠµ:
  - ì¦ê°€ëœ ê´€ì„± í•™ìŠµ
  - ì œì–´ ê²Œì¸ ìë™ ì¡°ì •
  - 200 ìƒ˜í”Œ ë‚´ ì ì‘ ì™„ë£Œ
```

---

## ì˜ˆìƒ ì„±ëŠ¥

### ì´ˆê¸° ëª¨ë¸ (10ì´ˆ ë°ì´í„°)

```
Training:
  - Samples: 200
  - Epochs: 50
  - Val loss: 0.005

Performance:
  - Sim RMSE: 0.01m  âœ… (ì‹œë®¬ë ˆì´ì…˜)
  - Real RMSE: 0.25m âŒ (ì‹¤ì œ ë¡œë´‡, domain shift)
```

### ì˜¨ë¼ì¸ í•™ìŠµ í›„ (60ì´ˆ)

```
Online Learning:
  - Total samples: 1200
  - Updates: 12 (100 ìƒ˜í”Œë§ˆë‹¤)
  - Buffer size: 500 (ìµœì‹  ë°ì´í„°ë§Œ ìœ ì§€)

Performance:
  - Real RMSE: 0.08m  âœ… (68% ê°œì„ !)
  - Model error: 0.002 â†’ 0.0005 (75% ê°ì†Œ)
  - Update time: 2-3s per update
```

---

## ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…

### ì£¼ìš” ì§€í‘œ

1. **Model Error**: ì˜ˆì¸¡ vs ì‹¤ì œ ì°¨ì´
   ```python
   predicted_state_dot = model.forward_dynamics(state, control)
   actual_state_dot = (next_state - state) / dt
   model_error = np.linalg.norm(predicted - actual)
   ```

2. **Tracking Error**: ì œì–´ ì„±ëŠ¥
   ```python
   tracking_error = np.linalg.norm(state[:2] - reference[:2])
   ```

3. **Update Frequency**: ì¬í•™ìŠµ ë¹ˆë„
   ```python
   updates_per_minute = num_updates / (total_time / 60)
   ```

### ì‹œê°í™”

ë°ëª¨ëŠ” ë‹¤ìŒì„ í”Œë¡¯í•©ë‹ˆë‹¤:
- XY ê¶¤ì 
- Tracking error (vs time)
- Model error (vs time)
- Number of updates (vs time)
- Buffer size (vs time)
- Model error distribution (before/after)

---

## ì œí•œì‚¬í•­

1. **ê³„ì‚° ë¹„ìš©**
   - Fine-tuningì€ ì‹¤ì‹œê°„ìœ¼ë¡œ ì‹¤í–‰
   - ë³µì¡í•œ ëª¨ë¸ì€ ì—…ë°ì´íŠ¸ ì§€ì—° ë°œìƒ

2. **Catastrophic Forgetting**
   - ìƒˆ í™˜ê²½ì— ê³¼ì í•©í•˜ë©´ ì´ì „ í™˜ê²½ ìŠìŒ
   - í•´ê²°: Replay buffer ë˜ëŠ” regularization

3. **ë°ì´í„° ë¶„í¬ ë³€í™”**
   - ê·¹ë‹¨ì  domain shiftëŠ” ì‹¤íŒ¨ ê°€ëŠ¥
   - í•´ê²°: Pre-trainingì„ ì¶©ë¶„íˆ + ì ì§„ì  ì ì‘

---

## ì¶”ê°€ ìë£Œ

- [LEARNED_MODELS_GUIDE.md](LEARNED_MODELS_GUIDE.md) - ì „ì²´ í•™ìŠµ ëª¨ë¸ ê°€ì´ë“œ
- [Neural Dynamics Learning Demo](../../examples/learned/neural_dynamics_learning_demo.py)
- [GP vs Neural Comparison Demo](../../examples/learned/gp_vs_neural_comparison_demo.py)
- [Online Learning Demo](../../examples/learned/online_learning_demo.py)

---

**ë¬¸ì„œ ì‘ì„±**: Claude Sonnet 4.5
**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2026-02-07
